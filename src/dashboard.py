import os
import streamlit as st
import pandas as pd
import plotly.express as px

from src.run_utils import latest_run_dir

ART_DIR = "artifacts"

st.set_page_config(page_title="Network KPI Anomaly Dashboard", layout="wide")
st.title("Network KPI Anomaly Dashboard")

st.markdown(
"""
This dashboard visualizes anomaly scores and alerts generated by the trained model.
Recommended flow:
1) Run training: `python -m src.train`
2) (Optional) Run eval: `python -m src.evaluate`
3) Start dashboard: `python -m streamlit run src/dashboard.py`
"""
)

@st.cache_data
def load_table(path_parquet: str, path_csv: str) -> pd.DataFrame:
    if os.path.exists(path_parquet):
        return pd.read_parquet(path_parquet)
    return pd.read_csv(path_csv)

def to_utc(ts) -> pd.Timestamp:
    """
    Convert slider datetime (could be tz-naive or tz-aware) into UTC tz-aware Timestamp.
    """
    t = pd.Timestamp(ts)
    if t.tzinfo is None:
        return t.tz_localize("UTC")
    return t.tz_convert("UTC")

mode = st.radio("Select data source", ["unlabeled (train data)", "labeled (eval data)"], horizontal=True)
if mode.startswith("unlabeled"):
    run_dir = latest_run_dir("train")
    if run_dir is None:
        st.error("No training run found. Run `python -m src.train` first.")
        st.stop()
    scored_path = os.path.join(run_dir, "scored_unlabeled.parquet")
    inc_path = os.path.join(run_dir, "incidents_unlabeled.parquet")
else:
    run_dir = latest_run_dir("eval")
    if run_dir is None:
        st.error("No evaluation run found. Run `python -m src.evaluate` first.")
        st.stop()
    scored_path = os.path.join(run_dir, "scored_labeled.parquet")
    inc_path = os.path.join(run_dir, "incidents_labeled.parquet")

csv_path = scored_path.replace(".parquet", ".csv")

if (not os.path.exists(scored_path)) and (not os.path.exists(csv_path)):
    st.error(f"File not found: {scored_path}. Run `python -m src.train` first.")
    st.stop()

df = load_table(scored_path, csv_path)
df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
df = df.dropna(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)

with st.sidebar:
    st.header("Controls")
    n_rows = len(df)
    st.caption(f"Rows: {n_rows:,}")

    tmin, tmax = df["timestamp"].min(), df["timestamp"].max()

    start, end = st.slider(
        "Time range",
        min_value=tmin.to_pydatetime(),
        max_value=tmax.to_pydatetime(),
        value=(tmin.to_pydatetime(), tmax.to_pydatetime())
    )

    show_alerts_only = st.checkbox("Show alerts only", value=False)

start_utc = to_utc(start)
end_utc = to_utc(end)

mask = (df["timestamp"] >= start_utc) & (df["timestamp"] <= end_utc)

d = df.loc[mask].copy()
if show_alerts_only:
    d = d[d["is_alert"] == True]

colA, colB = st.columns([2, 1])

with colA:
    fig = px.line(d, x="timestamp", y="anomaly_score", title="Anomaly Score (higher = more anomalous)")
    alerts = d[d["is_alert"] == True]
    if not alerts.empty:
        fig2 = px.scatter(alerts, x="timestamp", y="anomaly_score")
        for tr in fig2.data:
            fig.add_trace(tr)
    st.plotly_chart(fig, use_container_width=True)

with colB:
    st.subheader("Alert Summary")
    st.metric("Alert rate", f"{(df['is_alert'].mean()*100):.2f}%")

    if os.path.exists(inc_path) or os.path.exists(inc_path.replace(".parquet", ".csv")):
        inc_csv = inc_path.replace(".parquet", ".csv")
        inc = load_table(inc_path, inc_csv)
        st.metric("Incident count", int(len(inc)))
        st.dataframe(inc.tail(10), use_container_width=True)
    else:
        st.info("Incident file not found (run train/evaluate).")

st.subheader("KPI Overview")
kpi = st.selectbox("Select KPI", ["throughput", "congestion", "packet_loss", "latency", "jitter", "bandwidth"])
figk = px.line(d, x="timestamp", y=kpi, title=f"KPI: {kpi}")
st.plotly_chart(figk, use_container_width=True)

if mode.startswith("labeled") and "anomaly" in df.columns:
    st.subheader("Label vs Alerts (Labeled Data)")
    y_true = df["anomaly"].astype(int)
    y_pred = df["is_alert"].astype(int)
    tp = int(((y_true == 1) & (y_pred == 1)).sum())
    fp = int(((y_true == 0) & (y_pred == 1)).sum())
    fn = int(((y_true == 1) & (y_pred == 0)).sum())
    tn = int(((y_true == 0) & (y_pred == 0)).sum())
    st.write({"tp": tp, "fp": fp, "fn": fn, "tn": tn})
